{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Numpy of khairulice of Cervical_Cancer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiddenntreasure/Cervical-Cancer-Screening/blob/master/Numpy_of_khairulice_of_Cervical_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKyZpHilU5wg",
        "colab_type": "text"
      },
      "source": [
        "# Cervical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6yY7Ok1HTZf",
        "colab_type": "code",
        "outputId": "8d299e18-b155-465e-ed90-4a44f44ba636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFav9QmHpylj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN5z7ic5U9w3",
        "colab_type": "code",
        "outputId": "4cba1e7f-8b0d-4730-f0bd-a4942e38c620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "train_x = np.load('/content/drive/My Drive/Colab Notebooks/train.npy')\n",
        "train_y = np.load('/content/drive/My Drive/Colab Notebooks/train_labels.npy')\n",
        "#val_x = np.load('/content/drive/My Drive/Colab Notebooks/cervical/val.npy')\n",
        "#val_y = np.load('/content/drive/My Drive/Colab Notebooks/cervical/val_labels.npy')\n",
        "print(len(train_x), len(train_y))\n",
        "#print(len(val_x), len(val_y))\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8212 8212\n",
            "(8212, 200, 200, 3)\n",
            "(8212, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Zvs8klyix_",
        "colab_type": "text"
      },
      "source": [
        "# VGG-19 without bottlenect approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zUi49Pru1l7",
        "colab_type": "code",
        "outputId": "f7c9eafd-037e-4ba5-88d6-24200fec3908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.applications import VGG19\n",
        "conv_base = VGG19(weights='imagenet',include_top=False,input_shape=(200,200,3))\n",
        "\n",
        "from keras.applications import nasnet\n",
        "#conv_base = nasnet.NASNetMobile(weights='imagenet', include_top=False, input_shape=None)\n",
        "\n",
        "from keras.applications.resnet import ResNet152\n",
        "#conv_base = ResNet152(weights= 'imagenet', include_top=False, input_shape= (200,200,3))\n",
        "\n",
        "from keras.applications.densenet import DenseNet201\n",
        "#conv_base = DenseNet201(weights= 'imagenet', include_top=False, input_shape= (200,200,3))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OPLsENAg3Fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmNJODWdu2c_",
        "colab_type": "code",
        "outputId": "fb368b43-6ffe-4da4-e5e1-8ad3826714b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 6, 6, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 18432)             0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1gIo9hau60o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "#conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dLlz-7_fcfH",
        "colab_type": "code",
        "outputId": "0016881a-70fb-45d4-8db8-3a7e57eb6d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('This is the number of trainable weights ''before freezing the conv base:', len(model.trainable_weights))\n",
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'conv5_block20_0_relu':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "print('This is the number of trainable weights ''before freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 606\n",
            "This is the number of trainable weights before freezing the conv base: 82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZF_V6rgMn0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c5152fa3-3992-4bac-c0d3-8b1cc9f77bf6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train , x_val, y_train , y_val = train_test_split(train_x,train_y,test_size=0.3,stratify=train_y)\n",
        "\n",
        "print(len(x_train), len(y_train))\n",
        "print(len(x_val), len(y_val))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5748 5748\n",
            "2464 2464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpIRS-oTu-q8",
        "colab_type": "code",
        "outputId": "ea6d6f80-ae6a-4504-c091-4100624c0abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "batch_size = 50\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-5),metrics=['acc'])\n",
        "#model.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(train_datagen.flow(x_train,y_train, batch_size=batch_size, shuffle=True),\n",
        "    steps_per_epoch=5748//batch_size,\n",
        "    epochs=400,\n",
        "    validation_data=test_datagen.flow(x_val,y_val),\n",
        "    validation_steps=2464//batch_size,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "114/114 [==============================] - 65s 574ms/step - loss: 1.0885 - acc: 0.4230 - val_loss: 1.0691 - val_acc: 0.5236\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.06907, saving model to model-001-0.422955-0.523597.h5\n",
            "Epoch 2/400\n",
            "114/114 [==============================] - 63s 552ms/step - loss: 1.0822 - acc: 0.4461 - val_loss: 1.0459 - val_acc: 0.5249\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.06907 to 1.04594, saving model to model-002-0.446121-0.524872.h5\n",
            "Epoch 3/400\n",
            "114/114 [==============================] - 63s 552ms/step - loss: 1.0773 - acc: 0.4491 - val_loss: 1.0709 - val_acc: 0.5376\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.04594\n",
            "Epoch 4/400\n",
            "114/114 [==============================] - 63s 555ms/step - loss: 1.0798 - acc: 0.4600 - val_loss: 1.0337 - val_acc: 0.5261\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.04594 to 1.03373, saving model to model-004-0.459986-0.526148.h5\n",
            "Epoch 5/400\n",
            "114/114 [==============================] - 64s 565ms/step - loss: 1.0685 - acc: 0.4660 - val_loss: 1.0611 - val_acc: 0.5121\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.03373\n",
            "Epoch 6/400\n",
            "114/114 [==============================] - 63s 552ms/step - loss: 1.0665 - acc: 0.4751 - val_loss: 1.0294 - val_acc: 0.5281\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.03373 to 1.02940, saving model to model-006-0.475079-0.528061.h5\n",
            "Epoch 7/400\n",
            "114/114 [==============================] - 63s 550ms/step - loss: 1.0688 - acc: 0.4812 - val_loss: 1.0371 - val_acc: 0.5319\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.02940\n",
            "Epoch 8/400\n",
            "114/114 [==============================] - 62s 548ms/step - loss: 1.0628 - acc: 0.4868 - val_loss: 1.0339 - val_acc: 0.5395\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.02940\n",
            "Epoch 9/400\n",
            "114/114 [==============================] - 62s 546ms/step - loss: 1.0592 - acc: 0.4986 - val_loss: 1.0375 - val_acc: 0.5312\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.02940\n",
            "Epoch 10/400\n",
            "114/114 [==============================] - 62s 545ms/step - loss: 1.0581 - acc: 0.4930 - val_loss: 1.0527 - val_acc: 0.5338\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.02940\n",
            "Epoch 11/400\n",
            "114/114 [==============================] - 62s 544ms/step - loss: 1.0508 - acc: 0.5030 - val_loss: 1.0241 - val_acc: 0.5166\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.02940 to 1.02405, saving model to model-011-0.502984-0.516582.h5\n",
            "Epoch 12/400\n",
            "114/114 [==============================] - 62s 542ms/step - loss: 1.0488 - acc: 0.5049 - val_loss: 1.0466 - val_acc: 0.5217\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.02405\n",
            "Epoch 13/400\n",
            "114/114 [==============================] - 62s 541ms/step - loss: 1.0483 - acc: 0.5128 - val_loss: 1.0088 - val_acc: 0.5230\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.02405 to 1.00885, saving model to model-013-0.512812-0.522959.h5\n",
            "Epoch 14/400\n",
            "114/114 [==============================] - 61s 539ms/step - loss: 1.0462 - acc: 0.5040 - val_loss: 1.0500 - val_acc: 0.5370\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.00885\n",
            "Epoch 15/400\n",
            "114/114 [==============================] - 61s 537ms/step - loss: 1.0349 - acc: 0.5179 - val_loss: 1.0254 - val_acc: 0.5376\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.00885\n",
            "Epoch 16/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 1.0440 - acc: 0.5118 - val_loss: 1.0510 - val_acc: 0.5198\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.00885\n",
            "Epoch 17/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 1.0368 - acc: 0.5198 - val_loss: 1.0361 - val_acc: 0.5242\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.00885\n",
            "Epoch 18/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 1.0362 - acc: 0.5235 - val_loss: 1.0248 - val_acc: 0.5402\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.00885\n",
            "Epoch 19/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0351 - acc: 0.5230 - val_loss: 1.0689 - val_acc: 0.5293\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.00885\n",
            "Epoch 20/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0334 - acc: 0.5209 - val_loss: 1.0326 - val_acc: 0.5325\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.00885\n",
            "Epoch 21/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0298 - acc: 0.5297 - val_loss: 1.0070 - val_acc: 0.5223\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.00885 to 1.00704, saving model to model-021-0.529660-0.522321.h5\n",
            "Epoch 22/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0219 - acc: 0.5353 - val_loss: 1.0295 - val_acc: 0.5338\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.00704\n",
            "Epoch 23/400\n",
            "114/114 [==============================] - 61s 537ms/step - loss: 1.0248 - acc: 0.5367 - val_loss: 1.0205 - val_acc: 0.5402\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.00704\n",
            "Epoch 24/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 1.0263 - acc: 0.5335 - val_loss: 0.9567 - val_acc: 0.4994\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.00704 to 0.95666, saving model to model-024-0.533509-0.499362.h5\n",
            "Epoch 25/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0251 - acc: 0.5304 - val_loss: 1.0314 - val_acc: 0.5421\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.95666\n",
            "Epoch 26/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 1.0229 - acc: 0.5302 - val_loss: 1.0201 - val_acc: 0.5402\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.95666\n",
            "Epoch 27/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0190 - acc: 0.5256 - val_loss: 0.9693 - val_acc: 0.5249\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.95666\n",
            "Epoch 28/400\n",
            "114/114 [==============================] - 61s 533ms/step - loss: 1.0231 - acc: 0.5263 - val_loss: 0.9561 - val_acc: 0.5223\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.95666 to 0.95607, saving model to model-028-0.526334-0.522321.h5\n",
            "Epoch 29/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0221 - acc: 0.5277 - val_loss: 0.9763 - val_acc: 0.5351\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.95607\n",
            "Epoch 30/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0139 - acc: 0.5326 - val_loss: 1.0274 - val_acc: 0.5261\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.95607\n",
            "Epoch 31/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0156 - acc: 0.5316 - val_loss: 0.9802 - val_acc: 0.5370\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.95607\n",
            "Epoch 32/400\n",
            "114/114 [==============================] - 61s 533ms/step - loss: 1.0088 - acc: 0.5419 - val_loss: 0.9386 - val_acc: 0.5121\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.95607 to 0.93861, saving model to model-032-0.541945-0.512117.h5\n",
            "Epoch 33/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0097 - acc: 0.5286 - val_loss: 1.0227 - val_acc: 0.5421\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.93861\n",
            "Epoch 34/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0110 - acc: 0.5353 - val_loss: 0.9663 - val_acc: 0.5261\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.93861\n",
            "Epoch 35/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0132 - acc: 0.5286 - val_loss: 1.0100 - val_acc: 0.5332\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.93861\n",
            "Epoch 36/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0019 - acc: 0.5386 - val_loss: 0.8929 - val_acc: 0.5236\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.93861 to 0.89286, saving model to model-036-0.538610-0.523597.h5\n",
            "Epoch 37/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0100 - acc: 0.5288 - val_loss: 0.9454 - val_acc: 0.5293\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.89286\n",
            "Epoch 38/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0167 - acc: 0.5302 - val_loss: 1.0264 - val_acc: 0.5236\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.89286\n",
            "Epoch 39/400\n",
            "114/114 [==============================] - 61s 533ms/step - loss: 1.0068 - acc: 0.5358 - val_loss: 1.0174 - val_acc: 0.5338\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.89286\n",
            "Epoch 40/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0006 - acc: 0.5400 - val_loss: 0.8918 - val_acc: 0.5325\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.89286 to 0.89179, saving model to model-040-0.540000-0.532526.h5\n",
            "Epoch 41/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 1.0034 - acc: 0.5353 - val_loss: 0.9628 - val_acc: 0.5338\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.89179\n",
            "Epoch 42/400\n",
            "114/114 [==============================] - 61s 533ms/step - loss: 1.0036 - acc: 0.5347 - val_loss: 1.0162 - val_acc: 0.5357\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.89179\n",
            "Epoch 43/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 0.9995 - acc: 0.5367 - val_loss: 0.9580 - val_acc: 0.5153\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.89179\n",
            "Epoch 44/400\n",
            "114/114 [==============================] - 61s 533ms/step - loss: 0.9999 - acc: 0.5330 - val_loss: 1.0094 - val_acc: 0.5344\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.89179\n",
            "Epoch 45/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 1.0007 - acc: 0.5321 - val_loss: 0.9549 - val_acc: 0.5351\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.89179\n",
            "Epoch 46/400\n",
            "114/114 [==============================] - 61s 538ms/step - loss: 0.9997 - acc: 0.5349 - val_loss: 0.9509 - val_acc: 0.5204\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.89179\n",
            "Epoch 47/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 1.0005 - acc: 0.5249 - val_loss: 0.9514 - val_acc: 0.5268\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.89179\n",
            "Epoch 48/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 0.9952 - acc: 0.5428 - val_loss: 0.9524 - val_acc: 0.5478\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.89179\n",
            "Epoch 49/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 0.9976 - acc: 0.5377 - val_loss: 0.8409 - val_acc: 0.5166\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.89179 to 0.84088, saving model to model-049-0.537733-0.516582.h5\n",
            "Epoch 50/400\n",
            "114/114 [==============================] - 61s 534ms/step - loss: 0.9891 - acc: 0.5467 - val_loss: 0.9765 - val_acc: 0.5312\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.84088\n",
            "Epoch 51/400\n",
            "114/114 [==============================] - 61s 535ms/step - loss: 0.9949 - acc: 0.5230 - val_loss: 1.0331 - val_acc: 0.5172\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.84088\n",
            "Epoch 52/400\n",
            "114/114 [==============================] - 61s 538ms/step - loss: 0.9864 - acc: 0.5442 - val_loss: 0.9691 - val_acc: 0.5325\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.84088\n",
            "Epoch 53/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 0.9899 - acc: 0.5405 - val_loss: 1.1437 - val_acc: 0.5421\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.84088\n",
            "Epoch 54/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 0.9877 - acc: 0.5430 - val_loss: 0.8774 - val_acc: 0.5210\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.84088\n",
            "Epoch 55/400\n",
            "114/114 [==============================] - 61s 537ms/step - loss: 0.9848 - acc: 0.5428 - val_loss: 1.1398 - val_acc: 0.5306\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.84088\n",
            "Epoch 56/400\n",
            "114/114 [==============================] - 61s 536ms/step - loss: 0.9873 - acc: 0.5409 - val_loss: 0.9762 - val_acc: 0.5427\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.84088\n",
            "Epoch 57/400\n",
            " 91/114 [======================>.......] - ETA: 11s - loss: 0.9881 - acc: 0.5405"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNTorHtlIgXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('This is the number of trainable weights ''before freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RwsMzKiwU2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"/content/drive/My Drive/Colab Notebooks/cervical/model_vgg16_200_50epoch.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCMWICT_PW7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuZxkBVRR4sC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}